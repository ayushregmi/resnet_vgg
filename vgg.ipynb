{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rolexx/anaconda3/envs/project/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-28 21:56:18.219840: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-28 21:56:19.020996: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg_16(nn.Module):\n",
    "\n",
    "    '''\n",
    "    Vgg_16 model architecture.\n",
    "\n",
    "    Parameters:\n",
    "    - num_classes (int, optional): Number of classes in the classification task. Defaults to 1000.\n",
    "\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, num_classes=1000):\n",
    "        \n",
    "        super(Vgg_16, self).__init__()\n",
    "        \n",
    "        self.loss_log = []\n",
    "        self.accuracy_log = []\n",
    "        \n",
    "        self.convolution_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Linear(64*7*7, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            # nn.Linear(4096, 4096),\n",
    "            # nn.ReLU(True),\n",
    "            # nn.Dropout(),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        '''\n",
    "        Forward pass of the Vgg_16 model.\n",
    "\n",
    "        Parameters:\n",
    "        - x (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "        - torch.Tensor: Output tensor.\n",
    "        '''\n",
    "        \n",
    "        x = self.convolution_layers(x)\n",
    "        # print(x.shape)\n",
    "        x = self.avgpool(x)\n",
    "        # print(x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dense_layers(x)\n",
    "        return x\n",
    "    \n",
    "    def fit(self, data, loss_func=nn.CrossEntropyLoss, optimizer=optim.Adam, epochs=10, device=\"cpu\"):\n",
    "        \n",
    "        '''\n",
    "        Trains the Vgg_16 model.\n",
    "\n",
    "        Parameters:\n",
    "        - data (torch.utils.data.DataLoader): DataLoader providing the training data.\n",
    "        - loss_func (torch.nn.Module, optional): Loss function to be used for training. Defaults to nn.CrossEntropyLoss.\n",
    "        - optimizer (torch.optim.Optimizer, optional): Optimizer to be used for training. Defaults to optim.Adam.\n",
    "        - epochs (int, optional): Number of epochs for training. Defaults to 10.\n",
    "        - device (str, optional): Device to run the training on ('cpu' or 'cuda'). Defaults to \"cpu\".\n",
    "\n",
    "        '''\n",
    "        \n",
    "        self.to(device=device)\n",
    "        \n",
    "        loss_func = loss_func()\n",
    "        optimizer = optimizer(self.parameters(), lr=0.001)\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            self.train()\n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0\n",
    "            total_samples = 0\n",
    "            \n",
    "            for batch_idx, (images, labels) in enumerate(data):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = self(images)\n",
    "                \n",
    "                # print(labels.shape, outputs.shape)\n",
    "                \n",
    "                loss = loss_func(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_samples += labels.size(0)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                \n",
    "                # print(f\"Epoch: {epoch+1}\\tbatch:{batch_idx+1}\")\n",
    "                \n",
    "                            \n",
    "            epoch_loss = running_loss / len(data)\n",
    "            epoch_accuracy = correct_predictions / total_samples\n",
    "            \n",
    "            self.loss_log.append(epoch_loss)\n",
    "            self.accuracy_log.append(epoch_accuracy)\n",
    "            \n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {100 * epoch_accuracy:.2f}%')\n",
    "\n",
    "        \n",
    "    def evaluate(self, dataloader):\n",
    "        \n",
    "        '''\n",
    "        Evaluates the Vgg_16 model.\n",
    "\n",
    "        Parameters:\n",
    "        - dataloader (torch.utils.data.DataLoader): DataLoader providing the evaluation data.\n",
    "\n",
    "        Returns:\n",
    "        - float: Accuracy of the model on the evaluation data.\n",
    "        '''\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        self.to(device=device)\n",
    "        self.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in dataloader:\n",
    "                \n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                \n",
    "                outputs = self(images)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, dim=1)\n",
    "                \n",
    "                total_samples += labels.shape[0]\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                \n",
    "        \n",
    "        return correct_predictions / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(), # Convert PIL Image to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Normalize the pixel values to the range [-1, 1]\n",
    "])\n",
    "\n",
    "# Load FashionMNIST dataset\n",
    "fashion_mnist_train = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "fashion_mnist_test = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Limit the size of the train dataset to 10,000 samples\n",
    "train_indices = torch.randperm(len(fashion_mnist_train))[:5000]\n",
    "train_subset = torch.utils.data.Subset(fashion_mnist_train, train_indices)\n",
    "\n",
    "# Limit the size of the test dataset to 1,000 samples\n",
    "test_indices = torch.randperm(len(fashion_mnist_test))[:1000]\n",
    "test_subset = torch.utils.data.Subset(fashion_mnist_test, test_indices)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_subset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_subset, batch_size=64, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1648842"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Vgg_16(num_classes=10)\n",
    "\n",
    "\n",
    "sum(param.numel() for param in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"./model_vgg.pth\")\n",
    "model = torch.load(\"./model_vgg.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8264"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.813"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
