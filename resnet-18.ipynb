{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \n",
    "    '''\n",
    "    A residual block module for use in a neural network architecture.\n",
    "\n",
    "    Args:\n",
    "    - in_channels (int): Number of input channels.\n",
    "    - out_channels (int): Number of output channels.\n",
    "    - kernel_size (int, optional): Size of the convolutional kernel. Default is 3.\n",
    "    - stride (int, optional): Stride of the convolutional operation. Default is 1.\n",
    "\n",
    "    Attributes:\n",
    "    - layers (nn.Sequential): Sequential module containing convolutional layers, batch normalization, and ReLU activation.\n",
    "    - relu (nn.ReLU): ReLU activation function.\n",
    "    - adjust_conv_1 (nn.Conv2d): Convolutional layer for adjusting input channels to match output channels.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(  \n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(num_features=out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1),\n",
    "            nn.BatchNorm2d(num_features=out_channels),\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.adjust_conv_1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, stride=stride, kernel_size=kernel_size, padding=1)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \n",
    "        \"\"\"\n",
    "        Forward pass through the residual block.\n",
    "\n",
    "        Args:\n",
    "        - X (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "        - torch.Tensor: Output tensor after passing through the residual block.\n",
    "        \"\"\"\n",
    "        \n",
    "        out = self.layers(X)\n",
    "        \n",
    "        # print(\"output: \", out.shape)\n",
    "        # print(\"input_shape: \", X.shape)\n",
    "        X = self.adjust_conv_1(X)\n",
    "        \n",
    "        out += X\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    '''\n",
    "    A Residual Neural Network (ResNet) implementation using residual blocks for image classification.\n",
    "\n",
    "    Args:\n",
    "    - num_classes (int, optional): Number of classes in the classification task. Default is 10.\n",
    "\n",
    "    Attributes:\n",
    "    - loss_log (list): List to store the training loss for each epoch.\n",
    "    - accuracy_log (list): List to store the training accuracy for each epoch.\n",
    "    - residual_layers (nn.Sequential): Sequential module containing the residual blocks and final classification layer.\n",
    "\n",
    "    Methods:\n",
    "    - forward(X): Forward pass through the ResNet.\n",
    "    - fit(data, loss_func, optimizer, epochs, device): Train the ResNet on the provided data.\n",
    "    - evaluate(dataloader): Evaluate the performance of the trained ResNet on the provided dataloader.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.loss_log = []\n",
    "        self.accuracy_log = []\n",
    "        \n",
    "        self.residual_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=2, padding=1),\n",
    "            \n",
    "            ResidualBlock(in_channels=64, out_channels=64, kernel_size=3, stride=2),\n",
    "            ResidualBlock(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            \n",
    "            ResidualBlock(in_channels=64, out_channels=128, kernel_size=3, stride=2),\n",
    "            ResidualBlock(in_channels=128, out_channels=128, kernel_size=3, stride=1),\n",
    "            \n",
    "            # ResidualBlock(in_channels=128, out_channels=256, kernel_size=3, stride=2),\n",
    "            # ResidualBlock(in_channels=256, out_channels=256, kernel_size=3, stride=1),\n",
    "            \n",
    "            # ResidualBlock(in_channels=256, out_channels=512, kernel_size=3, stride=2),\n",
    "            # ResidualBlock(in_channels=512, out_channels=512, kernel_size=3, stride=1),\n",
    "            \n",
    "            \n",
    "            nn.AvgPool2d(kernel_size=7),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=2048, out_features=num_classes),\n",
    "        )\n",
    "        \n",
    "        # # conv1: input (3, 224, 224) -> output: (64, 112, 112)\n",
    "        # self.layer_1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2)\n",
    "        \n",
    "        # # conv2_x: input(64, 112, 112) -> output: (64, 56, 56)\n",
    "        # self.max_pool_2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        # self.res_block_2_1 = ResidualBlock(in_channels=64, out_channels=64, kernel_size=3, stride=2)\n",
    "        # self.res_block_2_2 = ResidualBlock(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
    "        \n",
    "        # # conv3_x: input(64, 56, 56) -> output: (128, 28, 28)\n",
    "        # self.res_block_3_1 = ResidualBlock(in_channels=64, out_channels=128, kernel_size=3, stride=2)\n",
    "        # self.res_block_3_2 = ResidualBlock(in_channels=128, out_channels=128, kernel_size=3, stride=1)\n",
    "        \n",
    "        # # conv4_x: input(128, 28, 28) -> output: (256, 14, 14)\n",
    "        # self.res_block_3_1 = ResidualBlock(in_channels=128, out_channels=256, kernel_size=3, stride=2)\n",
    "        # self.res_block_3_2 = ResidualBlock(in_channels=256, out_channels=256, kernel_size=3, stride=1)\n",
    "        \n",
    "        # # conv5_x: input(256, 14, 14) -> output: (512, 7, 7)\n",
    "        # self.res_block_3_1 = ResidualBlock(in_channels=256, out_channels=512, kernel_size=3, stride=2)\n",
    "        # self.res_block_3_2 = ResidualBlock(in_channels=512, out_channels=512, kernel_size=3, stride=1)\n",
    "        \n",
    "        # # dense layers\n",
    "        # self.avg_pool = nn.AvgPool2d(kernel_size=7)\n",
    "        # self.flatten = nn.Flatten()\n",
    "        # self.linear_layer = nn.Linear(in_features=512, out_features=output_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        \"\"\"\n",
    "        Forward pass through the ResNet.\n",
    "\n",
    "        Args:\n",
    "        - X (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "        - torch.Tensor: Output tensor after passing through the ResNet.\n",
    "        \"\"\"\n",
    "        \n",
    "        out = self.residual_layers(X)\n",
    "        return out\n",
    "    \n",
    "    def fit(self, data, loss_func=nn.CrossEntropyLoss, optimizer=optim.Adam, epochs=10, device=\"cpu\"):\n",
    "        \n",
    "        \"\"\"\n",
    "        Train the ResNet on the provided data.\n",
    "\n",
    "        Args:\n",
    "        - data (torch.utils.data.DataLoader): Data loader containing training data.\n",
    "        - loss_func (torch.nn.modules.loss._Loss, optional): Loss function for training. Default is nn.CrossEntropyLoss.\n",
    "        - optimizer (torch.optim.Optimizer, optional): Optimizer for training. Default is optim.Adam.\n",
    "        - epochs (int, optional): Number of epochs for training. Default is 10.\n",
    "        - device (str, optional): Device to use for training, 'cpu' or 'cuda'. Default is 'cpu'.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.to(device=device)\n",
    "        \n",
    "        loss_func = loss_func()\n",
    "        optimizer = optimizer(self.parameters(), lr=0.001)\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            self.train()\n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0\n",
    "            total_samples = 0\n",
    "            \n",
    "            for images, labels in data:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = self(images)\n",
    "                \n",
    "                # print(labels.shape, outputs.shape)\n",
    "                \n",
    "                loss = loss_func(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_samples += labels.size(0)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "            \n",
    "            epoch_loss = running_loss / len(data)\n",
    "            epoch_accuracy = correct_predictions / total_samples\n",
    "            \n",
    "            self.loss_log.append(epoch_loss)\n",
    "            self.accuracy_log.append(epoch_accuracy)\n",
    "            \n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {100 * epoch_accuracy:.2f}%')\n",
    "\n",
    "        print('Finished Training')\n",
    "        \n",
    "    def evaluate(self, dataloader):\n",
    "        \n",
    "        \"\"\"\n",
    "        Evaluate the performance of the trained ResNet on the provided dataloader.\n",
    "\n",
    "        Args:\n",
    "        - dataloader (torch.utils.data.DataLoader): Data loader containing evaluation data.\n",
    "\n",
    "        Returns:\n",
    "        - float: Accuracy of the ResNet on the evaluation data.\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        self.to(device=device)\n",
    "        self.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in dataloader:\n",
    "                \n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                \n",
    "                outputs = self(images)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, dim=1)\n",
    "                \n",
    "                total_samples += labels.shape[0]\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                \n",
    "        \n",
    "        return correct_predictions / total_samples\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(), # Convert PIL Image to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Normalize the pixel values to the range [-1, 1]\n",
    "])\n",
    "\n",
    "# Load FashionMNIST dataset\n",
    "fashion_mnist_train = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "fashion_mnist_test = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=fashion_mnist_train, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=fashion_mnist_test, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ResNet(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.4161, Accuracy: 84.63%\n",
      "Epoch [2/10], Loss: 0.2593, Accuracy: 90.67%\n",
      "Epoch [3/10], Loss: 0.2205, Accuracy: 92.09%\n",
      "Epoch [4/10], Loss: 0.1947, Accuracy: 93.00%\n",
      "Epoch [5/10], Loss: 0.1777, Accuracy: 93.45%\n",
      "Epoch [6/10], Loss: 0.1610, Accuracy: 94.14%\n",
      "Epoch [7/10], Loss: 0.1491, Accuracy: 94.62%\n",
      "Epoch [8/10], Loss: 0.1339, Accuracy: 95.22%\n",
      "Epoch [9/10], Loss: 0.1215, Accuracy: 95.70%\n",
      "Epoch [10/10], Loss: 0.1060, Accuracy: 96.21%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "m.fit(train_loader, device=device, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(m, \"./model_resnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./model_resnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9611166666666666"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9221"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
